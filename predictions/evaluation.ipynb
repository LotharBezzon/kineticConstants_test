{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021508a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "# and go up one level to the project root ('KINETICCONSTANTS_TEST')\n",
    "project_root = os.path.abspath(\"..\")\n",
    "\n",
    "# Add the project root to the system path if it's not there already\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78efb611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Dataset, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj, dense_to_sparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lmdb\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import SimpleGNN, mlp\n",
    "import os\n",
    "from simulation.produce_simulations import SimulatedGraphDataset\n",
    "from simulation.simulator import Simulator, find_cycles_for_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = '../model_checkpoints'  # Directory to load checkpoints\n",
    "ckpt = 2\n",
    "num_nodes = 113\n",
    "num_edges = 350\n",
    "#model = mlp(in_channels=int(num_nodes), out_channel=int(num_edges), hidden_dim=[int(0.5*num_nodes), int(0.3*num_nodes), int(0.2*num_nodes), int(0.1*num_nodes)], hidden_num=4)\n",
    "model = SimpleGNN(in_channels=1, hidden_channels=64, node_out_channels=2, edge_out_channels=2)\n",
    "model.load_state_dict(torch.load(os.path.join(ckpt_dir, f'model_checkpoint_epoch_{ckpt}.pt')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dcef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '../simulation/simulated_graph_dataset_only_steady_state_free_energies'\n",
    "dataset = SimulatedGraphDataset(root=db_path)\n",
    "torch.manual_seed(42)\n",
    "dataset = dataset.shuffle()  # Shuffle the dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = dataset[:train_size], dataset[train_size:]\n",
    "small_test_dataset = test_dataset[:500]\n",
    "small_train_dataset = train_dataset[:500]\n",
    "\n",
    "batch_size = 32  # Adjust batch size as needed\n",
    "test_loader = DataLoader(small_test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "train_loader = DataLoader(small_train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aac398",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix_df = pd.read_csv('../simulation/adjacency_matrix.csv', index_col=0)\n",
    "all_lipids = adj_matrix_df.index.tolist()\n",
    "adj_matrix = np.array(adj_matrix_df)\n",
    "symmetric_adj_matrix = np.maximum(adj_matrix, adj_matrix.T)\n",
    "adj_matrix = symmetric_adj_matrix\n",
    "num_edges = np.sum(adj_matrix, dtype=int)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "print(f'Number of edges: {num_edges}')\n",
    "correlation_matrix_partial = pd.read_csv('../simulation/correlation_matrix.csv', index_col=0)\n",
    "correlation_matrix = pd.DataFrame(np.eye(len(all_lipids)), index=all_lipids, columns=all_lipids)\n",
    "L = np.linalg.cholesky(correlation_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ca951",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edges = 378\n",
    "ks_pred = {f'k_{idx}': np.array([]) for idx in range(num_edges)}\n",
    "ks_true = {f'k_{idx}': np.array([]) for idx in range(num_edges)}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            data = batch.to('cpu')\n",
    "            node_out, edge_out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            k_prod, k_deg, sigma_conc, dropout = node_out.split([1, 1, 1, 1], dim=-1)\n",
    "            k, sigma_k = edge_out.split([1, 1], dim=-1)\n",
    "            k = k.squeeze(-1)\n",
    "            k_prod = k_prod.squeeze(-1)\n",
    "            k_deg = k_deg.squeeze(-1)\n",
    "            pred = k.cpu().numpy()\n",
    "            targets = np.array(batch.parameters['sparse_log_kinetic_constants'])\n",
    "            \n",
    "            for idx in range(num_edges):\n",
    "                ks_pred[f'k_{idx}'] = np.append(ks_pred[f'k_{idx}'], np.array(pred[idx::batch.batch_size]))\n",
    "                ks_true[f'k_{idx}'] = np.append(ks_true[f'k_{idx}'], np.array(targets[idx::batch.batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f23660",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_pred = [np.array([]) for idx in range(num_edges)]\n",
    "ks_true = [np.array([]) for idx in range(num_edges)]\n",
    "\n",
    "ks_prod_pred = [np.array([]) for idx in range(num_nodes)]\n",
    "ks_deg_pred = [np.array([]) for idx in range(num_nodes)]\n",
    "ks_prod_true = [np.array([]) for idx in range(num_nodes)]\n",
    "ks_deg_true = [np.array([]) for idx in range(num_nodes)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_loader, desc=\"Evaluating\"):\n",
    "        data = batch.to('cpu')\n",
    "        out_node, out_edge = model(data.x, data.edge_index , data.batch)\n",
    "        k_prod, k_deg, sigma_conc, dropout = out_node.split([1, 1, 1, 1], dim=-1)\n",
    "        k, sigma_k = out_edge.split([1, 1], dim=-1)\n",
    "        k = k.squeeze(-1)\n",
    "        k_prod = k_prod.squeeze(-1)\n",
    "        k_deg = k_deg.squeeze(-1)\n",
    "        pred = k.cpu().numpy()\n",
    "        targets = np.array(batch.parameters['sparse_log_kinetic_constants']).reshape(-1)\n",
    "        prod_targets = np.log(np.array(batch.parameters['production_constants']).reshape(-1))\n",
    "        deg_targets = np.log(np.array(batch.parameters['degradation_constants']).reshape(-1))\n",
    "    \n",
    "        for idx in range(num_nodes):\n",
    "            ks_prod_pred[idx] =  np.append(ks_prod_pred[idx], np.array(k_prod.cpu().numpy()[idx::num_nodes]))\n",
    "            ks_deg_pred[idx] =  np.append(ks_deg_pred[idx], np.array(k_deg.cpu().numpy()[idx::num_nodes]))\n",
    "            ks_prod_true[idx] =  np.append(ks_prod_true[idx], np.array(prod_targets[idx::num_nodes]))\n",
    "            ks_deg_true[idx] =  np.append(ks_deg_true[idx], np.array(deg_targets[idx::num_nodes]))\n",
    "        \n",
    "        for idx in range(num_edges):\n",
    "            ks_pred[idx] = np.append(ks_pred[idx], np.array(pred[idx::num_edges]))\n",
    "            ks_true[idx] = np.append(ks_true[idx], np.array(targets[idx::num_edges]))\n",
    "\n",
    "ks_pred = np.array(ks_pred)\n",
    "ks_true = np.array(ks_true)\n",
    "ks_prod_pred = np.array(ks_prod_pred)\n",
    "ks_deg_pred = np.array(ks_deg_pred)\n",
    "ks_prod_true = np.array(ks_prod_true)\n",
    "ks_deg_true = np.array(ks_deg_true)\n",
    "\n",
    "print(ks_pred.shape, ks_true.shape)\n",
    "print(ks_prod_pred.shape, ks_deg_pred.shape)\n",
    "print(ks_prod_true.shape, ks_deg_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_num_nodes = 2 * num_nodes\n",
    "deltaG_true = [np.array([]) for idx in range(num_edges)]\n",
    "deltaG_pred = [np.array([]) for idx in range(num_edges)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_loader, desc=\"Evaluating\"):\n",
    "        node_out, edge_out = model(batch.x, batch.edge_index, batch.batch, free_energies=False)\n",
    "        bath_free_energies, bath_barriers = node_out.split([ 1, 1], dim=-1)\n",
    "        deltaG, barrier_heights = edge_out.split([ 1, 1], dim=-1)\n",
    "        \n",
    "        deltaG_true_batch = torch.tensor(np.array(batch.parameters['sparse_deltaG']), dtype=torch.float32)\n",
    "        deltaG_true_batch = deltaG_true_batch.reshape(-1)\n",
    "        deltaG = deltaG.squeeze(-1)\n",
    "\n",
    "        for idx in range(num_edges):\n",
    "            deltaG_pred[idx] =  np.append(deltaG_pred[idx], np.array(deltaG.cpu().numpy()[idx::num_edges]))\n",
    "            deltaG_true[idx] =  np.append(deltaG_true[idx], np.array(deltaG_true_batch.cpu().numpy()[idx::num_edges]))\n",
    "deltaG_true = np.array(deltaG_true)\n",
    "deltaG_pred = np.array(deltaG_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.where(adj_matrix == 1)\n",
    "edges = list(zip(edges[0], edges[1]))\n",
    "num_cycles_per_edge = []\n",
    "for idx in range(np.sum(adj_matrix, dtype=int)):\n",
    "    cycles = find_cycles_for_edge(edges[idx][0], edges[idx][1], adj_matrix, max_cycle_length=6)\n",
    "    num_cycles_per_edge.append(np.sum(cycles))\n",
    "num_cycles_per_edge = np.array(num_cycles_per_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(true, pred, title, per_sample=False, indexes=range(40)):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=8, ncols=5, figsize=(20, 32), tight_layout=True)#, subplot_kw={'xscale': 'log', 'yscale': 'log'})\n",
    "    for i, idx in enumerate(indexes[:40]):\n",
    "        row = i // 5\n",
    "        col = i % 5\n",
    "        if per_sample:\n",
    "            true_values = true[:, idx]\n",
    "            pred_values = pred[:, idx]\n",
    "        else:\n",
    "            true_values = true[idx]\n",
    "            pred_values = pred[idx]\n",
    "        axs[row, col].scatter(true_values, pred_values, alpha=0.5)\n",
    "        axs[row, col].plot([min(true_values), max(true_values)],\n",
    "                        [min(true_values), max(true_values)], 'r--')\n",
    "        axs[row, col].axhline(y=np.mean(true_values), color='gray', linestyle='dotted')\n",
    "        axs[row, col].set_title(f'{title}{idx}')\n",
    "        axs[row, col].set_xlabel('True Values')\n",
    "        axs[row, col].set_ylabel('Predicted Values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46896de",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.argsort(num_cycles_per_edge)[:40]\n",
    "plot_results(ks_true, ks_pred, title='Kinetic Constant k_', indexes=indexes)\n",
    "plot_results(ks_true, ks_pred, title='Sample ', per_sample=True, indexes=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(ks_prod_true, ks_prod_pred, title='Kinetic Constant k_')\n",
    "plot_results(ks_prod_true, ks_prod_pred, title='Sample ', per_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c62e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(deltaG_true, deltaG_pred, title='Free Energy node ')\n",
    "plot_results(deltaG_true, deltaG_pred, title='Sample ', per_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb80de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "ckpt = 2\n",
    "# --- CONFIGURATION ---\n",
    "# Replace these with your actual file paths\n",
    "model_path = os.path.join(ckpt_dir, f'model_checkpoint_epoch_{ckpt}.pt')\n",
    "optim_path = os.path.join(ckpt_dir, f'optimizer_checkpoint_epoch_{ckpt}.pt')\n",
    "\n",
    "# 1. Load the Checkpoints\n",
    "print(f\"Loading {model_path} and {optim_path}...\")\n",
    "model_state = torch.load(model_path, map_location='cpu')\n",
    "optim_state = torch.load(optim_path, map_location='cpu')\n",
    "\n",
    "# 2. Get the Parameter Map\n",
    "# The optimizer stores params in the exact order they appear in the model.\n",
    "# We extract the 'state' dictionary which contains the momentum buffers.\n",
    "optim_internals = optim_state['state']\n",
    "param_groups = optim_state['param_groups']\n",
    "\n",
    "# Extract the list of parameter IDs used by the optimizer\n",
    "# (Usually there is only 1 param_group, unless you used different learning rates)\n",
    "param_ids = param_groups[0]['params'] \n",
    "\n",
    "print(f\"\\n{'LAYER NAME':<40} | {'STATUS':<15} | {'GRAD SIGNAL (exp_avg)':<20}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "# 3. Iterate through Model Parameters and Match with Optimizer State\n",
    "# model_state.keys() gives us the layer names\n",
    "# param_ids gives us the optimizer's internal ID for that layer\n",
    "for i, (layer_name, _) in enumerate(model_state.items()):\n",
    "    \n",
    "    # Safety check: Ensure we don't go out of bounds if lengths differ\n",
    "    if i >= len(param_ids): break\n",
    "    \n",
    "    pid = param_ids[i]\n",
    "    \n",
    "    # Check if this parameter has a stored state in the optimizer\n",
    "    if pid in optim_internals:\n",
    "        stats = optim_internals[pid]\n",
    "        \n",
    "        # 'exp_avg' is the Moving Average of the Gradient (Momentum)\n",
    "        if 'exp_avg' in stats:\n",
    "            grad_avg = stats['exp_avg']\n",
    "            \n",
    "            # Calculate magnitude (average absolute value)\n",
    "            magnitude = torch.mean(torch.abs(grad_avg)).item()\n",
    "            \n",
    "            # Formatting the output\n",
    "            status = \"HEALTHY\"\n",
    "            if magnitude < 1e-6: status = \"DEAD/SATURATED\"\n",
    "            elif magnitude > 100: status = \"EXPLODING\"\n",
    "            \n",
    "            print(f\"{layer_name:<40} | {status:<15} | {magnitude:.2e}\")\n",
    "        else:\n",
    "            print(f\"{layer_name:<40} | {'NO MOMENTUM':<15} | N/A\")\n",
    "    else:\n",
    "        # Some params (like buffers) might not be updated by the optimizer\n",
    "        print(f\"{layer_name:<40} | {'NOT TRAINED':<15} | N/A\")\n",
    "\n",
    "print(\"-\" * 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kinetic_constants_to_equilibrium_constants(log_kinetic_constants, adj_matrix):\n",
    "    num_nodes = adj_matrix.shape[0]\n",
    "    num_samples = log_kinetic_constants.shape[1]\n",
    "    num_reactions = np.sum(adj_matrix, dtype=int) // 2\n",
    "    K_eq = np.ones((num_reactions, num_samples))\n",
    "    counter = 0\n",
    "    for i in range(num_nodes):\n",
    "        connected_indices = np.where(adj_matrix[i] == 1)[0]\n",
    "        for j in connected_indices:\n",
    "            if i < j:  # To avoid double counting\n",
    "                reaction_index = np.sum(adj_matrix[:i], dtype=int) + np.sum(adj_matrix[i, :j], dtype=int)\n",
    "                k_forward = log_kinetic_constants[reaction_index]\n",
    "                k_reverse = log_kinetic_constants[np.sum(adj_matrix[:j], dtype=int) + np.sum(adj_matrix[j, :i], dtype=int)]\n",
    "                print(f'Reaction {counter}: k_forward index {reaction_index}, k_reverse index {np.sum(adj_matrix[:j], dtype=int) + np.sum(adj_matrix[j, :i], dtype=int)}')\n",
    "                K_eq[counter] = k_forward - k_reverse\n",
    "                counter += 1\n",
    "    return K_eq\n",
    "\n",
    "num_reactions = np.sum(adj_matrix, dtype=int) // 2\n",
    "Ks_pred = kinetic_constants_to_equilibrium_constants(np.array(ks_pred), adj_matrix)\n",
    "Ks_true = kinetic_constants_to_equilibrium_constants(np.array(ks_true), adj_matrix)\n",
    "Ks_bath_true = ks_prod_true - ks_deg_true\n",
    "Ks_bath_pred = ks_prod_pred - ks_deg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.argsort(num_cycles_per_edge[::5])[:40]\n",
    "print(np.sort(num_cycles_per_edge[::5])[:40])\n",
    "plot_results(Ks_true, Ks_pred, title='Equilibrium Constant ', indexes=indexes)\n",
    "plot_results(Ks_true, Ks_pred, title='Sample ', per_sample=True, indexes=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(Ks_bath_true, Ks_bath_pred, title='Equilibrium Constant ')\n",
    "plot_results(Ks_bath_true, Ks_bath_pred, title='Sample ', per_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    _, _, embeddings = model(batch.x, batch.edge_index, batch.batch, return_embeddings=True)\n",
    "    # 3. Check for Oversmoothing (Standard Deviation)\n",
    "    # Calculate the standard deviation across nodes for each feature dimension\n",
    "    # Shape of embeddings: [Num_Nodes, Hidden_Channels]\n",
    "    std_per_feature = torch.std(embeddings, dim=0)\n",
    "\n",
    "    # The average standard deviation across all features\n",
    "    avg_diversity = std_per_feature.mean().item()\n",
    "\n",
    "    print(f\"Average Node Diversity (Std Dev): {avg_diversity:.6f}\")\n",
    "\n",
    "    # DIAGNOSIS:\n",
    "    if avg_diversity < 1e-2:\n",
    "        print(\"CRITICAL: Your nodes have collapsed (Oversmoothing). They are all the same.\")\n",
    "    elif avg_diversity < 1e-1:\n",
    "        print(\"WARNING: Low diversity. Potential saturation or smoothing.\")\n",
    "    else:\n",
    "        print(\"HEALTHY: Nodes have distinct representations.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d046416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "embeddings_list = []\n",
    "for batch in test_loader:\n",
    "    _, _, embeddings = model(batch.x, batch.edge_index, batch.batch, return_embeddings=True)\n",
    "    embeddings_list.append(embeddings)\n",
    "\n",
    "embeddings_all = torch.cat(embeddings_list, dim=0).detach().cpu().numpy()\n",
    "'''tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(embeddings_all)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.6)\n",
    "ax.set_title(\"t-SNE Visualization of Node Embeddings\")\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd131f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "embeddings_pca = pca.fit_transform(embeddings_all)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Explained variance by each principal component:\")\n",
    "for i, var in enumerate(explained_variance):\n",
    "    print(f\"PC {i+1}: {var:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29459279",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator()\n",
    "mask = np.where(adj_matrix == 1)\n",
    "nodes_to_track = [i for i in range(adj_matrix.shape[0])]\n",
    "true_kinetic_constants = np.full_like(adj_matrix, fill_value=-np.inf)\n",
    "true_kinetic_constants[mask] = ks_true[:,0]\n",
    "predicted_kinetic_constants = np.full_like(adj_matrix, fill_value=-np.inf)\n",
    "predicted_kinetic_constants[mask] = ks_pred[:,0]\n",
    "kin = np.stack([true_kinetic_constants, predicted_kinetic_constants])\n",
    "prod = np.stack([ks_prod_true.T[0,:], ks_prod_true.T[0,:]])\n",
    "deg = np.stack([ks_deg_true.T[0,:], ks_deg_true.T[0,:]])\n",
    "print(kin.shape, prod.shape, deg.shape)\n",
    "simulator.set_simulation_parameters(log_kinetic_constants=kin,\n",
    "                                    log_production_constants=prod,\n",
    "                                    log_degradation_constants=deg)\n",
    "simulator.run_equilibration(track_concentrations=nodes_to_track[5::10], track_reference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "correlation_matrix_partial = pd.read_csv('../simulation/correlation_matrix.csv', index_col=0)\n",
    "symm_adj_df = pd.DataFrame(adj_matrix, index=adj_matrix_df.index, columns=adj_matrix_df.columns)\n",
    "# add columns and rows to correlation matrix to match the adjacency matrix\n",
    "correlation_matrix_partial = correlation_matrix_partial.reindex(index=symm_adj_df.index, columns=symm_adj_df.columns, fill_value=0)\n",
    "# set digonal to 1\n",
    "np.fill_diagonal(correlation_matrix_partial.values, 1)\n",
    "ax = sns.clustermap(correlation_matrix_partial, cmap='coolwarm', cbar=True, vmin=-1, vmax=1, annot=False)\n",
    "linkage_matrix = ax.dendrogram_row.linkage\n",
    "num_clusters = 2\n",
    "cluster_labels = fcluster(linkage_matrix, t=num_clusters, criterion='maxclust')\n",
    "clean_labels = cluster_labels.tolist()\n",
    "for i in range(num_clusters):\n",
    "    cluster_list = [adj_matrix_df.index[j] for j in range(len(cluster_labels)) if clean_labels[j] == i+1]\n",
    "    print(f'Cluster {i+1}: {cluster_list} \\nCluster Size: {len(cluster_list)}\\n')\n",
    "\n",
    "node_to_cluster = {adj_matrix_df.index[i]: clean_labels[i] for i in range(len(cluster_labels))}\n",
    "\n",
    "\n",
    "G = nx.from_pandas_adjacency(symm_adj_df)\n",
    "nx.set_node_attributes(G, node_to_cluster, name='group')\n",
    "for node, group_id in node_to_cluster.items():\n",
    "    # The 'title' attribute controls what shows up on Hover\n",
    "    # We can use HTML inside this string (e.g., <br> for new lines)\n",
    "    G.nodes[node]['title'] = f\"Cluster {group_id}\"\n",
    "    G.nodes[node]['group'] = group_id\n",
    "# 2. Create the PyVis network\n",
    "net = Network(notebook=True, height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", cdn_resources='remote')\n",
    "\n",
    "# 3. Translate from NetworkX to PyVis\n",
    "net.from_nx(G)\n",
    "\n",
    "# 4. Add physics controls (optional, helps you tweak the layout in real-time)\n",
    "net.show_buttons(filter_=['physics'])\n",
    "\n",
    "# 5. Save and show\n",
    "net.show(f\"{num_clusters}_clusters.html\")\n",
    "ax\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv) - kineticConstants_test",
   "language": "python",
   "name": "kineticconstants_test_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
